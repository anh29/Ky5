{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trọng số w: [2.03984748 2.85169313]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "def mini_batch_gradient_descent(X, y, batch_size=10, learning_rate=0.01, n_epochs=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros(n_features)  # Khởi tạo trọng số ban đầu\n",
    "    losses = []  # Lưu lại các giá trị của hàm loss trong quá trình tìm nghiệm\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_epoch = 0\n",
    "        # Trộn ngẫu nhiên thứ tự các mẫu trong tập huấn luyện\n",
    "        shuffled_indices = np.random.permutation(n_samples)\n",
    "        X_shuffled = X[shuffled_indices]\n",
    "        y_shuffled = y[shuffled_indices]\n",
    "        # Chia tập huấn luyện thành các batchs\n",
    "        n_batches = n_samples // batch_size\n",
    "        X_batches = np.array_split(X_shuffled, n_batches)\n",
    "        y_batches = np.array_split(y_shuffled, n_batches)\n",
    "        for i in range(n_batches):\n",
    "            # Lấy một batch từ tập huấn luyện\n",
    "            X_batch = X_batches[i]\n",
    "            y_batch = y_batches[i]\n",
    "            # Tính đạo hàm của hàm loss đối với các mẫu trong batch\n",
    "            y_pred = np.dot(X_batch, w)\n",
    "            gradient = -2 * np.dot(X_batch.T, y_batch - y_pred) / batch_size\n",
    "            # Cập nhật trọng số w\n",
    "            w -= learning_rate * gradient\n",
    "            # Cập nhật giá trị của loss trong epoch hiện tại\n",
    "            loss_epoch += mse_loss(y_batch, y_pred)\n",
    "        # Lưu lại giá trị loss trong epoch hiện tại\n",
    "        losses.append(loss_epoch / n_batches)\n",
    "\n",
    "    return w, losses\n",
    "# Tạo dữ liệu mô phỏng\n",
    "X = np.random.rand(100, 2)\n",
    "y = np.dot(X, np.array([2, 3])) + np.random.randn(100)\n",
    "# Thực hiện tìm nghiệm bằng Mini-Batch Gradient Descent\n",
    "w, losses = mini_batch_gradient_descent(X, y)\n",
    "print('Trọng số w:', w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
